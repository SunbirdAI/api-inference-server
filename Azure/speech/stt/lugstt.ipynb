{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-ai-ml azure-identity"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-ml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.8.0)\nRequirement already satisfied: azure-identity in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.13.0)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (6.0)\nRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.27.1)\nRequirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.4.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (3.19.0)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.17.3)\nRequirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.65.0)\nRequirement already satisfied: strictyaml<2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.7.3)\nRequirement already satisfied: colorama<0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (2.7.0)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.16.0)\nRequirement already satisfied: azure-storage-file-share<13.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.12.0)\nRequirement already satisfied: azure-storage-file-datalake<13.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (12.11.0)\nRequirement already satisfied: pydash<6.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (5.1.2)\nRequirement already satisfied: isodate in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (0.6.1)\nRequirement already satisfied: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nRequirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (4.6.3)\nRequirement already satisfied: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-ml) (1.1.9)\nRequirement already satisfied: cryptography>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity) (41.0.1)\nRequirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity) (1.22.0)\nRequirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity) (1.0.0)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-identity) (1.16.0)\nRequirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (2.31.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.3)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (23.0)\nRequirement already satisfied: portalocker<3,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.7.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (2023.5.7)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\nRequirement already satisfied: opencensus<1.0.0,>=0.11.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.2)\nRequirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.0)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\nRequirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.11.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.26.16)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.59.1)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.20.3)\nRequirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.20.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.3.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.5.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# deployment\n",
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.identity import DefaultAzureCredential"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693990026444
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter details of your Azure Machine Learning workspace\n",
        "subscription_id = \"1c623b04-20a0-4b59-897e-ceef40c48e27\"\n",
        "resource_group = \"OasisAi_group\"\n",
        "workspace = \"oasisAi\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693990026621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693990026893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "endpoint_name = \"lugtts-endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name = endpoint_name, \n",
        "    description=\"This is the endpoint for inferencing text to speech in luganda\",\n",
        "    auth_mode=\"key\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693991629214
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(path=\"Conda.yaml\")\n",
        "env = Environment(\n",
        "    conda_file=\"Conda.yaml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        ")\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=model,\n",
        "    environment=env,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"Inference\", scoring_script=\"Score.py\"\n",
        "    ),\n",
        "    instance_type=\"STANDARD_NC6S_V3\",\n",
        "    instance_count=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693995280006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Updating local endpoint (lugtts-endpt-09060913290567) Done (0m 0s)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32800/score', 'openapi_uri': None, 'name': 'lugtts-endpt-09060913290567', 'description': 'This is the endpoint for inferencing text to speech in luganda', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiSpeechToText'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f57a8433ac0>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 68,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693995284143
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(\n",
        "    deployment=blue_deployment, local=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Updating local deployment (lugtts-endpt-09060913290567 / blue) .\nBuilding Docker image from Dockerfile\nStep 1/6 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n ---> a79caa0393e2\nStep 2/6 : RUN mkdir -p /var/azureml-app/\n ---> Using cache\n ---> 5286c4c3769f\nStep 3/6 : WORKDIR /var/azureml-app/\n ---> Using cache\n ---> 0e4d45b04cdc\nStep 4/6 : COPY conda.yml /var/azureml-app/\n ---> Using cache\n ---> 543a8d7da2f9\nStep 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n ---> Using cache\n ---> 64097cdae03c\nStep 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n ---> Using cache\n ---> 338e497468c1\nSuccessfully built 338e497468c1\nSuccessfully tagged lugtts-endpt-09060913290567:blue\n\nStarting up endpoint.....Done (0m 30s)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 69,
          "data": {
            "text/plain": "ManagedOnlineDeployment({'private_network_connection': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'lugtts-endpt-09060913290567', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiSpeechToText'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f57a99dc970>, 'model': Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': '68f10e26af33c7674813d7aeb9e06991', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiSpeechToText'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f57a834e350>, 'version': '1', 'latest_version': None, 'path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiSpeechToText/Conda.yaml', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': None}), 'code_configuration': {'code': 'Inference'}, 'environment': Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiSpeechToText'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f57a834de10>, 'version': 'cfe4321fa61e23b618a835bd177f6014', 'latest_version': None, 'conda_file': {'name': 'lugstt-model', 'channels': ['conda-forge', 'defaults'], 'dependencies': ['python == 3.9', 'pip', {'pip': ['azureml-defaults==1.47.0', 'pyyaml', 'sentencepiece', 'azure-storage-blob', 'torch', 'librosa', 'inference-schema[numpy-support]==1.5', 'transformers', 'pyctcdecode==0.4.0', 'kenlm', 'scipy == 1.7.1', 'numpy == 1.21.2', 'setuptools']}]}, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- python == 3.9\\n- pip\\n- pip:\\n  - azureml-defaults==1.47.0\\n  - pyyaml\\n  - sentencepiece\\n  - azure-storage-blob\\n  - torch\\n  - librosa\\n  - inference-schema[numpy-support]==1.5\\n  - transformers\\n  - pyctcdecode==0.4.0\\n  - kenlm\\n  - scipy == 1.7.1\\n  - numpy == 1.21.2\\n  - setuptools\\nname: lugstt-model\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'data_collector': None, 'egress_public_network_access': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 69,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693995317652
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=endpoint_name, local=True, lines=500\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "\"2023-09-06T10:14:59,888720714+00:00 - rsyslog/run \\r\\n2023-09-06T10:14:59,891979275+00:00 - nginx/run \\r\\n2023-09-06T10:14:59,893132996+00:00 - gunicorn/run \\r\\n2023-09-06T10:14:59,894736726+00:00 | gunicorn/run | \\r\\n2023-09-06T10:14:59,896267955+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-06T10:14:59,897846084+00:00 | gunicorn/run | AzureML Container Runtime Information\\r\\n2023-09-06T10:14:59,899429014+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-06T10:14:59,901108445+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:00,398893566+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:00,401678118+00:00 | gunicorn/run | AzureML image information: openmpi3.1.2-ubuntu18.04, Materializaton Build:20230227.v3\\r\\n2023-09-06T10:15:00,403029843+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:00,404412969+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:00,405740494+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/inf-conda-env/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\r\\n2023-09-06T10:15:00,407096119+00:00 | gunicorn/run | PYTHONPATH environment variable: \\r\\n2023-09-06T10:15:00,408380743+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:00,841604955+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\\r\\n\\r\\n# conda environments:\\r\\n#\\r\\nbase                     /opt/miniconda\\r\\ninf-conda-env         *  /opt/miniconda/envs/inf-conda-env\\r\\n\\r\\n2023-09-06T10:15:01,804265079+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:01,805783007+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\r\\n\\r\\nadal==1.2.7\\r\\nargcomplete==2.1.2\\r\\nattrs==23.1.0\\r\\naudioread==3.0.0\\r\\nazure-common==1.1.28\\r\\nazure-core==1.29.3\\r\\nazure-graphrbac==0.61.1\\r\\nazure-identity==1.7.0\\r\\nazure-mgmt-authorization==2.0.0\\r\\nazure-mgmt-containerregistry==10.1.0\\r\\nazure-mgmt-core==1.4.0\\r\\nazure-mgmt-keyvault==10.2.3\\r\\nazure-mgmt-resource==21.2.1\\r\\nazure-mgmt-storage==20.1.0\\r\\nazure-storage-blob==12.17.0\\r\\nazureml-core==1.47.0\\r\\nazureml-dataprep==4.5.7\\r\\nazureml-dataprep-native==38.0.0\\r\\nazureml-dataprep-rslex==2.11.4\\r\\nazureml-dataset-runtime==1.47.0\\r\\nazureml-defaults==1.47.0\\r\\nazureml-inference-server-http==0.7.7\\r\\nbackports.tempfile==1.0\\r\\nbackports.weakref==1.0.post1\\r\\nbcrypt==4.0.1\\r\\nblinker==1.6.2\\r\\ncachetools==5.3.1\\r\\ncertifi==2023.7.22\\r\\ncffi==1.15.1\\r\\ncharset-normalizer==3.2.0\\r\\nclick==8.1.7\\r\\ncloudpickle==2.2.1\\r\\ncmake==3.27.4.1\\r\\nconfigparser==3.7.4\\r\\ncontextlib2==21.6.0\\r\\ncryptography==38.0.4\\r\\ndecorator==5.1.1\\r\\ndistro==1.8.0\\r\\ndocker==6.1.3\\r\\ndotnetcore2==3.1.23\\r\\nexceptiongroup==1.1.3\\r\\nfilelock==3.12.3\\r\\nFlask==2.3.3\\r\\nFlask-Cors==3.0.10\\r\\nfsspec==2023.9.0\\r\\nfusepy==3.0.1\\r\\ngoogle-api-core==2.11.1\\r\\ngoogle-auth==2.22.0\\r\\ngoogleapis-common-protos==1.60.0\\r\\ngunicorn==20.1.0\\r\\nhuggingface-hub==0.16.4\\r\\nhumanfriendly==10.0\\r\\nhypothesis==6.84.1\\r\\nidna==3.4\\r\\nimportlib-metadata==6.8.0\\r\\ninference-schema==1.5\\r\\nisodate==0.6.1\\r\\nitsdangerous==2.1.2\\r\\njeepney==0.8.0\\r\\nJinja2==3.1.2\\r\\njmespath==1.0.1\\r\\njoblib==1.3.2\\r\\njson-logging-py==0.2\\r\\njsonpickle==2.2.0\\r\\njsonschema==4.19.0\\r\\njsonschema-specifications==2023.7.1\\r\\nkenlm==0.2.0\\r\\nknack==0.10.1\\r\\nlazy_loader==0.3\\r\\nlibrosa==0.10.1\\r\\nlit==16.0.6\\r\\nllvmlite==0.40.1\\r\\nMarkupSafe==2.1.3\\r\\nmpmath==1.3.0\\r\\nmsal==1.23.0\\r\\nmsal-extensions==0.3.1\\r\\nmsgpack==1.0.5\\r\\nmsrest==0.7.1\\r\\nmsrestazure==0.6.4\\r\\nndg-httpsclient==0.5.1\\r\\nnetworkx==3.1\\r\\nnumba==0.57.1\\r\\nnumpy==1.21.2\\r\\nnvidia-cublas-cu11==11.10.3.66\\r\\nnvidia-cuda-cupti-cu11==11.7.101\\r\\nnvidia-cuda-nvrtc-cu11==11.7.99\\r\\nnvidia-cuda-runtime-cu11==11.7.99\\r\\nnvidia-cudnn-cu11==8.5.0.96\\r\\nnvidia-cufft-cu11==10.9.0.58\\r\\nnvidia-curand-cu11==10.2.10.91\\r\\nnvidia-cusolver-cu11==11.4.0.1\\r\\nnvidia-cusparse-cu11==11.7.4.91\\r\\nnvidia-nccl-cu11==2.14.3\\r\\nnvidia-nvtx-cu11==11.7.91\\r\\noauthlib==3.2.2\\r\\nopencensus==0.11.2\\r\\nopencensus-context==0.1.3\\r\\nopencensus-ext-azure==1.1.9\\r\\npackaging==21.3\\r\\nparamiko==2.12.0\\r\\npathspec==0.11.2\\r\\npkginfo==1.9.6\\r\\nplatformdirs==3.10.0\\r\\npooch==1.7.0\\r\\nportalocker==2.7.0\\r\\nprotobuf==4.24.2\\r\\npsutil==5.9.5\\r\\npyarrow==9.0.0\\r\\npyasn1==0.5.0\\r\\npyasn1-modules==0.3.0\\r\\npycparser==2.21\\r\\npyctcdecode==0.4.0\\r\\nPygments==2.16.1\\r\\npygtrie==2.5.0\\r\\nPyJWT==2.8.0\\r\\nPyNaCl==1.5.0\\r\\npyOpenSSL==22.1.0\\r\\npyparsing==3.1.1\\r\\nPySocks==1.7.1\\r\\npython-dateutil==2.8.2\\r\\npytz==2023.3.post1\\r\\nPyYAML==6.0.1\\r\\nreferencing==0.30.2\\r\\nregex==2023.8.8\\r\\nrequests==2.31.0\\r\\nrequests-oauthlib==1.3.1\\r\\nrpds-py==0.10.2\\r\\nrsa==4.9\\r\\nsafetensors==0.3.3\\r\\nscikit-learn==1.3.0\\r\\nscipy==1.7.1\\r\\nSecretStorage==3.3.3\\r\\nsentencepiece==0.1.99\\r\\nsix==1.16.0\\r\\nsortedcontainers==2.4.0\\r\\nsoundfile==0.12.1\\r\\nsoxr==0.3.6\\r\\nsympy==1.12\\r\\ntabulate==0.9.0\\r\\nthreadpoolctl==3.2.0\\r\\ntokenizers==0.13.3\\r\\ntorch==2.0.1\\r\\ntqdm==4.66.1\\r\\ntransformers==4.33.0\\r\\ntriton==2.0.0\\r\\ntyping_extensions==4.7.1\\r\\nurllib3==1.26.16\\r\\nwebsocket-client==1.6.2\\r\\nWerkzeug==2.3.7\\r\\nwrapt==1.12.1\\r\\nzipp==3.16.2\\r\\n\\r\\n2023-09-06T10:15:02,275108395+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:02,276652824+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-06T10:15:02,278139552+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\\r\\n2023-09-06T10:15:02,279550378+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-06T10:15:02,280900303+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:03,700888790+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:03,702411419+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-06T10:15:03,703919547+00:00 | gunicorn/run | AzureML Inference Server\\r\\n2023-09-06T10:15:03,705366074+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-06T10:15:03,706812801+00:00 | gunicorn/run | \\r\\n2023-09-06T10:15:05,204242638+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\r\\n\\r\\nAzure ML Inferencing HTTP server v0.7.7\\r\\n\\r\\n\\r\\nServer Settings\\r\\n---------------\\r\\nEntry Script Name: /var/azureml-app/Inference/Score.py\\r\\nModel Directory: /var/azureml-app/azureml-models//68f10e26af33c7674813d7aeb9e06991/1\\r\\nWorker Count: 1\\r\\nWorker Timeout (seconds): 300\\r\\nServer Port: 31311\\r\\nApplication Insights Enabled: false\\r\\nApplication Insights Key: None\\r\\nInferencing HTTP server version: azmlinfsrv/0.7.7\\r\\nCORS for the specified origins: None\\r\\n\\r\\n\\r\\nServer Routes\\r\\n---------------\\r\\nLiveness Probe: GET   127.0.0.1:31311/\\r\\nScore:          POST  127.0.0.1:31311/score\\r\\n\\r\\nStarting gunicorn 20.1.0\\r\\nListening at: http://0.0.0.0:31311 (25)\\r\\nUsing worker: sync\\r\\nBooting worker with pid: 88\\r\\nInitializing logger\\r\\nStarting up app insights client\\r\\n2023-09-06 10:15:05,780 | root | INFO | Starting up app insights client\\r\\nlogging socket was found. logging is available.\\r\\nlogging socket was found. logging is available.\\r\\nStarting up app insight hooks\\r\\n2023-09-06 10:15:05,785 | root | INFO | Starting up app insight hooks\\r\\nFound user script at /var/azureml-app/Inference/Score.py\\r\\n2023-09-06 10:15:07,448 | root | INFO | Found user script at /var/azureml-app/Inference/Score.py\\r\\nrun() is not decorated. Server will invoke it with the input in JSON string.\\r\\n2023-09-06 10:15:07,448 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\\r\\nInvoking user's init function\\r\\n2023-09-06 10:15:07,448 | root | INFO | Invoking user's init function\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)rocessor_config.json:   0% 0.00/262 [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)rocessor_config.json: 100% 262/262 [00:00<00:00, 71.1kB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)olve/main/vocab.json:   0% 0.00/580 [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)olve/main/vocab.json: 100% 580/580 [00:00<00:00, 148kB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)in/added_tokens.json:   0% 0.00/3.00 [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)in/added_tokens.json: 100% 3.00/3.00 [00:00<00:00, 1.74kB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)cial_tokens_map.json:   0% 0.00/93.0 [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)cial_tokens_map.json: 100% 93.0/93.0 [00:00<00:00, 58.8kB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)lve/main/config.json:   0% 0.00/2.32k [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)lve/main/config.json: 100% 2.32k/2.32k [00:00<00:00, 1.40MB/s]\\r\\n00000000-0000-0000-0000-000000000000,Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\\r\\n00000000-0000-0000-0000-000000000000,\\rFetching 4 files:   0% 0/4 [00:00<?, ?it/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)47d8fd/alphabet.json:   0% 0.00/374 [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)47d8fd/alphabet.json: 100% 374/374 [00:00<00:00, 104kB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)age_model/attrs.json:   0% 0.00/78.0 [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)age_model/attrs.json: 100% 78.0/78.0 [00:00<00:00, 21.2kB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)e_model/unigrams.txt:   0% 0.00/1.53M [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading 5gram.bin:   0% 0.00/74.7M [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)e_model/unigrams.txt: 100% 1.53M/1.53M [00:00<00:00, 6.34MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)e_model/unigrams.txt: 100% 1.53M/1.53M [00:00<00:00, 6.29MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading 5gram.bin:  28% 21.0M/74.7M [00:00<00:00, 169MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading 5gram.bin:  56% 41.9M/74.7M [00:00<00:00, 42.0MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading 5gram.bin:  70% 52.4M/74.7M [00:01<00:00, 39.9MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading 5gram.bin:  84% 62.9M/74.7M [00:01<00:00, 44.9MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\x1b[A\\x1b[A\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading 5gram.bin: 100% 74.7M/74.7M [00:01<00:00, 52.6MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rFetching 4 files:  50% 2/4 [00:01<00:01,  1.10it/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rFetching 4 files: 100% 4/4 [00:01<00:00,  2.21it/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   0% 0.00/1.26G [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   2% 21.0M/1.26G [00:00<00:19, 63.8MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   3% 41.9M/1.26G [00:00<00:16, 71.8MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   5% 62.9M/1.26G [00:00<00:15, 75.6MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   6% 73.4M/1.26G [00:01<00:17, 66.3MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   7% 94.4M/1.26G [00:01<00:18, 63.2MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:   9% 115M/1.26G [00:01<00:17, 65.0MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  10% 126M/1.26G [00:01<00:16, 68.1MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  11% 136M/1.26G [00:01<00:15, 72.7MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  12% 147M/1.26G [00:02<00:15, 70.0MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  12% 157M/1.26G [00:02<00:15, 70.2MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  13% 168M/1.26G [00:02<00:17, 62.8MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  14% 178M/1.26G [00:02<00:18, 57.4MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  16% 199M/1.26G [00:02<00:15, 68.8MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  17% 220M/1.26G [00:03<00:18, 55.6MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  19% 241M/1.26G [00:03<00:16, 60.5MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  20% 252M/1.26G [00:03<00:16, 60.6MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading pytorch_model.bin:  22% 273M/1.26G [00:04<00:15, 64.7MB/s]\\r\\n\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693995317916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.get(name=endpoint_name, local=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32797/score', 'openapi_uri': None, 'name': 'lugtts-endpt-09060913290567', 'description': 'This is the endpoint for inferencing text to speech in luganda', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiSpeechToText'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f57a84de6b0>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693995078173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=endpoint_name,\n",
        "    request_file=\"sample-request.json\",\n",
        "    local=True,\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 72,
          "data": {
            "text/plain": "'{\"result\": \"namatugoga nawulira nga ekigambo gwo ekikuvaako ennyuma nga kyogera nti nalyo ekkubo mu litambula munaakyamirga ku mukono ogwa ddyo era bwe munaakyamira nga ku gwa kkono nga tutunuulira yesu yekka omukulu okukkiriza kwaffe omutuukiriza waakwo olwo essanyu eriteeka mu maaso agumiikiriza omusaalaba nga anyuma ensonyi atuula ku mukono ogwa ddyo ogwa ntebe ya katonda\"}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1693995602845
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}