{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting azure-ai-ml\n",
            "  Downloading azure_ai_ml-1.9.0-py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: azure-identity in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (1.13.0)\n",
            "Collecting azure-storage-file-datalake<13.0.0\n",
            "  Downloading azure_storage_file_datalake-12.12.0-py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (4.65.0)\n",
            "Collecting marshmallow<4.0.0,>=3.5\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (2.7.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (4.17.3)\n",
            "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (12.13.0)\n",
            "Requirement already satisfied: isodate in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (0.6.1)\n",
            "Requirement already satisfied: opencensus-ext-azure<2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.1.9)\n",
            "Collecting azure-storage-file-share<13.0.0\n",
            "  Downloading azure_storage_file_share-12.13.0-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (4.6.3)\n",
            "Requirement already satisfied: azure-common<2.0.0,>=1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.1.28)\n",
            "Collecting pydash<6.0.0\n",
            "  Downloading pydash-5.1.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.27.1)\n",
            "Collecting strictyaml<2.0.0\n",
            "  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msrest>=0.6.18 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (0.7.1)\n",
            "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-ai-ml) (1.4.0)\n",
            "Collecting colorama<0.5.0\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: msal<2.0.0,>=1.20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-identity) (1.22.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-identity) (41.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-identity) (1.16.0)\n",
            "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-identity) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml) (2.31.0)\n",
            "Collecting azure-storage-blob<13.0.0,>=12.10.0\n",
            "  Downloading azure_storage_blob-12.17.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.23.0\n",
            "  Downloading azure_core-1.29.3-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.4/191.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cryptography>=2.5->azure-identity) (1.15.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (5.12.0)\n",
            "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (1.3.10)\n",
            "Requirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (23.1)\n",
            "Requirement already satisfied: portalocker<3,>=1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from msrest>=0.6.18->azure-ai-ml) (2023.5.7)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (5.9.5)\n",
            "Requirement already satisfied: opencensus<1.0.0,>=0.11.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml) (0.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (3.15.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.11.1)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.1.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (1.26.16)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-ml) (3.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (1.59.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (3.19.6)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (2.20.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (5.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure<2.0.0->azure-ai-ml) (0.5.0)\n",
            "Installing collected packages: pydash, marshmallow, colorama, strictyaml, azure-core, azure-storage-file-share, azure-storage-blob, azure-storage-file-datalake, azure-ai-ml\n",
            "  Attempting uninstall: azure-core\n",
            "    Found existing installation: azure-core 1.27.1\n",
            "    Uninstalling azure-core-1.27.1:\n",
            "      Successfully uninstalled azure-core-1.27.1\n",
            "  Attempting uninstall: azure-storage-blob\n",
            "    Found existing installation: azure-storage-blob 12.13.0\n",
            "    Uninstalling azure-storage-blob-12.13.0:\n",
            "      Successfully uninstalled azure-storage-blob-12.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "azureml-mlflow 1.51.0 requires azure-storage-blob<=12.13.0,>=12.5.0, but you have azure-storage-blob 12.17.0 which is incompatible.\n",
            "azureml-core 1.51.0.post1 requires packaging<=23.0,>=20.0, but you have packaging 23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed azure-ai-ml-1.9.0 azure-core-1.29.3 azure-storage-blob-12.17.0 azure-storage-file-datalake-12.12.0 azure-storage-file-share-12.13.0 colorama-0.4.6 marshmallow-3.20.1 pydash-5.1.2 strictyaml-1.7.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install azure-ai-ml azure-identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1693906318473
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# deployment\n",
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1693906321989
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# enter details of your Azure Machine Learning workspace\n",
        "subscription_id = \"\"\n",
        "resource_group = \"\"\n",
        "workspace = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1693906326157
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1693906330257
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "endpoint_name = \"lugtts-endpt-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name = endpoint_name, \n",
        "    description=\"This is the endpoint for inferencing text to speech in luganda\",\n",
        "    auth_mode=\"key\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1693908775160
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = Model(path=\"Conda.yaml\")\n",
        "env = Environment(\n",
        "    conda_file=\"Conda.yaml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
        ")\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=model,\n",
        "    environment=env,\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"Inference\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    instance_type=\"STANDARD_NC6S_V3\",\n",
        "    instance_count=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1693908782808
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating local endpoint (lugtts-endpt-09050932965776) .Done (0m 5s)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32779/score', 'openapi_uri': None, 'name': 'lugtts-endpt-09050932965776', 'description': 'This is the endpoint for inferencing text to speech in luganda', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f341c146d30>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1693908816288
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Updating local deployment (lugtts-endpt-09050932965776 / blue) .\n",
            "Building Docker image from Dockerfile\n",
            "Step 1/6 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
            " ---> a79caa0393e2\n",
            "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> 5286c4c3769f\n",
            "Step 3/6 : WORKDIR /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> 0e4d45b04cdc\n",
            "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
            " ---> Using cache\n",
            " ---> b04334c2c08b\n",
            "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
            " ---> Using cache\n",
            " ---> 4c1daffd08b5\n",
            "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
            " ---> Using cache\n",
            " ---> fb5dfeb89421\n",
            "Successfully built fb5dfeb89421\n",
            "Successfully tagged lugtts-endpt-09050932965776:blue\n",
            "\n",
            "Starting up endpoint.....Done (0m 30s)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineDeployment({'private_network_connection': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'lugtts-endpt-09050932965776', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f341c1a6730>, 'model': Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': '1d0f1822b9d2d9cdd296f41b2e8b5c4b', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f341c193dc0>, 'version': '1', 'latest_version': None, 'path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech/Conda.yaml', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': None}), 'code_configuration': {'code': 'Inference'}, 'environment': Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f341c1935b0>, 'version': 'eff168ddb0966b7bfda87f5266785c99', 'latest_version': None, 'conda_file': {'name': 'lugtts-model-env', 'channels': ['conda-forge', 'defaults'], 'dependencies': ['python == 3.9', 'pip', {'pip': ['azureml-defaults==1.47.0', 'pyyaml', 'azure-storage-blob', 'inference-schema[numpy-support]==1.5', 'speechbrain', 'torch', 'torchaudio', 'scipy == 1.7.1', 'numpy == 1.21.2', 'setuptools']}]}, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'build': None, 'inference_config': None, 'os_type': None, 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- conda-forge\\n- defaults\\ndependencies:\\n- python == 3.9\\n- pip\\n- pip:\\n  - azureml-defaults==1.47.0\\n  - pyyaml\\n  - azure-storage-blob\\n  - inference-schema[numpy-support]==1.5\\n  - speechbrain\\n  - torch\\n  - torchaudio\\n  - scipy == 1.7.1\\n  - numpy == 1.21.2\\n  - setuptools\\nname: lugtts-model-env\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'data_collector': None, 'egress_public_network_access': None})"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_deployments.begin_create_or_update(\n",
        "    deployment=blue_deployment, local=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1693908834489
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32782/score', 'openapi_uri': None, 'name': 'lugtts-endpt-09050932965776', 'description': 'This is the endpoint for inferencing text to speech in luganda', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f341c187310>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.get(name=endpoint_name, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1693908836539
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"2023-09-05T10:13:18,098964551+00:00 - rsyslog/run \\r\\n2023-09-05T10:13:18,100753732+00:00 - nginx/run \\r\\n2023-09-05T10:13:18,105157084+00:00 - gunicorn/run \\r\\n2023-09-05T10:13:18,109158040+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:18,110741023+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-05T10:13:18,112304406+00:00 | gunicorn/run | AzureML Container Runtime Information\\r\\n2023-09-05T10:13:18,113717990+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-05T10:13:18,115139175+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:18,537961870+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:18,540446843+00:00 | gunicorn/run | AzureML image information: openmpi3.1.2-ubuntu18.04, Materializaton Build:20230227.v3\\r\\n2023-09-05T10:13:18,541689929+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:18,542956915+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:18,544224302+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/inf-conda-env/bin:/opt/miniconda/condabin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\r\\n2023-09-05T10:13:18,545496188+00:00 | gunicorn/run | PYTHONPATH environment variable: \\r\\n2023-09-05T10:13:18,546717574+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:18,927882523+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\\r\\n\\r\\n# conda environments:\\r\\n#\\r\\nbase                     /opt/miniconda\\r\\ninf-conda-env         *  /opt/miniconda/envs/inf-conda-env\\r\\n\\r\\n2023-09-05T10:13:19,752747439+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:19,754063024+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\r\\n\\r\\nadal==1.2.7\\r\\nargcomplete==2.1.2\\r\\nattrs==23.1.0\\r\\nazure-common==1.1.28\\r\\nazure-core==1.29.3\\r\\nazure-graphrbac==0.61.1\\r\\nazure-identity==1.7.0\\r\\nazure-mgmt-authorization==2.0.0\\r\\nazure-mgmt-containerregistry==10.1.0\\r\\nazure-mgmt-core==1.4.0\\r\\nazure-mgmt-keyvault==10.2.3\\r\\nazure-mgmt-resource==21.2.1\\r\\nazure-mgmt-storage==20.1.0\\r\\nazure-storage-blob==12.17.0\\r\\nazureml-core==1.47.0\\r\\nazureml-dataprep==4.5.7\\r\\nazureml-dataprep-native==38.0.0\\r\\nazureml-dataprep-rslex==2.11.4\\r\\nazureml-dataset-runtime==1.47.0\\r\\nazureml-defaults==1.47.0\\r\\nazureml-inference-server-http==0.7.7\\r\\nbackports.tempfile==1.0\\r\\nbackports.weakref==1.0.post1\\r\\nbcrypt==4.0.1\\r\\nblinker==1.6.2\\r\\ncachetools==5.3.1\\r\\ncertifi==2023.7.22\\r\\ncffi==1.15.1\\r\\ncharset-normalizer==3.2.0\\r\\nclick==8.1.7\\r\\ncloudpickle==2.2.1\\r\\ncmake==3.27.2\\r\\nconfigparser==3.7.4\\r\\ncontextlib2==21.6.0\\r\\ncryptography==38.0.4\\r\\ndistro==1.8.0\\r\\ndocker==6.1.3\\r\\ndotnetcore2==3.1.23\\r\\nfilelock==3.12.3\\r\\nFlask==2.3.3\\r\\nFlask-Cors==3.0.10\\r\\nfsspec==2023.9.0\\r\\nfusepy==3.0.1\\r\\ngoogle-api-core==2.11.1\\r\\ngoogle-auth==2.22.0\\r\\ngoogleapis-common-protos==1.60.0\\r\\ngunicorn==20.1.0\\r\\nhuggingface-hub==0.16.4\\r\\nhumanfriendly==10.0\\r\\nHyperPyYAML==1.2.1\\r\\nidna==3.4\\r\\nimportlib-metadata==6.8.0\\r\\ninference-schema==1.5\\r\\nisodate==0.6.1\\r\\nitsdangerous==2.1.2\\r\\njeepney==0.8.0\\r\\nJinja2==3.1.2\\r\\njmespath==1.0.1\\r\\njoblib==1.3.2\\r\\njson-logging-py==0.2\\r\\njsonpickle==2.2.0\\r\\njsonschema==4.19.0\\r\\njsonschema-specifications==2023.7.1\\r\\nknack==0.10.1\\r\\nlit==16.0.6\\r\\nMarkupSafe==2.1.3\\r\\nmpmath==1.3.0\\r\\nmsal==1.23.0\\r\\nmsal-extensions==0.3.1\\r\\nmsrest==0.7.1\\r\\nmsrestazure==0.6.4\\r\\nndg-httpsclient==0.5.1\\r\\nnetworkx==3.1\\r\\nnumpy==1.21.2\\r\\nnvidia-cublas-cu11==11.10.3.66\\r\\nnvidia-cuda-cupti-cu11==11.7.101\\r\\nnvidia-cuda-nvrtc-cu11==11.7.99\\r\\nnvidia-cuda-runtime-cu11==11.7.99\\r\\nnvidia-cudnn-cu11==8.5.0.96\\r\\nnvidia-cufft-cu11==10.9.0.58\\r\\nnvidia-curand-cu11==10.2.10.91\\r\\nnvidia-cusolver-cu11==11.4.0.1\\r\\nnvidia-cusparse-cu11==11.7.4.91\\r\\nnvidia-nccl-cu11==2.14.3\\r\\nnvidia-nvtx-cu11==11.7.91\\r\\noauthlib==3.2.2\\r\\nopencensus==0.11.2\\r\\nopencensus-context==0.1.3\\r\\nopencensus-ext-azure==1.1.9\\r\\npackaging==21.3\\r\\nparamiko==2.12.0\\r\\npathspec==0.11.2\\r\\npkginfo==1.9.6\\r\\nportalocker==2.7.0\\r\\nprotobuf==4.24.2\\r\\npsutil==5.9.5\\r\\npyarrow==9.0.0\\r\\npyasn1==0.5.0\\r\\npyasn1-modules==0.3.0\\r\\npycparser==2.21\\r\\nPygments==2.16.1\\r\\nPyJWT==2.8.0\\r\\nPyNaCl==1.5.0\\r\\npyOpenSSL==22.1.0\\r\\npyparsing==3.1.1\\r\\nPySocks==1.7.1\\r\\npython-dateutil==2.8.2\\r\\npytz==2023.3.post1\\r\\nPyYAML==6.0.1\\r\\nreferencing==0.30.2\\r\\nrequests==2.31.0\\r\\nrequests-oauthlib==1.3.1\\r\\nrpds-py==0.10.2\\r\\nrsa==4.9\\r\\nruamel.yaml==0.17.28\\r\\nruamel.yaml.clib==0.2.7\\r\\nscipy==1.7.1\\r\\nSecretStorage==3.3.3\\r\\nsentencepiece==0.1.99\\r\\nsix==1.16.0\\r\\nspeechbrain==0.5.15\\r\\nsympy==1.12\\r\\ntabulate==0.9.0\\r\\ntorch==2.0.1\\r\\ntorchaudio==2.0.2\\r\\ntqdm==4.66.1\\r\\ntriton==2.0.0\\r\\ntyping_extensions==4.7.1\\r\\nurllib3==1.26.16\\r\\nwebsocket-client==1.6.2\\r\\nWerkzeug==2.3.7\\r\\nwrapt==1.12.1\\r\\nzipp==3.16.2\\r\\n\\r\\n2023-09-05T10:13:20,151699094+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:20,152966880+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-05T10:13:20,154211066+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\\r\\n2023-09-05T10:13:20,155425953+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-05T10:13:20,156661840+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:20,998652463+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:21,000008748+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-05T10:13:21,001274134+00:00 | gunicorn/run | AzureML Inference Server\\r\\n2023-09-05T10:13:21,002498720+00:00 | gunicorn/run | ###############################################\\r\\n2023-09-05T10:13:21,003720507+00:00 | gunicorn/run | \\r\\n2023-09-05T10:13:21,969836516+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\r\\n\\r\\nAzure ML Inferencing HTTP server v0.7.7\\r\\n\\r\\n\\r\\nServer Settings\\r\\n---------------\\r\\nEntry Script Name: /var/azureml-app/Inference/score.py\\r\\nModel Directory: /var/azureml-app/azureml-models//1d0f1822b9d2d9cdd296f41b2e8b5c4b/1\\r\\nWorker Count: 1\\r\\nWorker Timeout (seconds): 300\\r\\nServer Port: 31311\\r\\nApplication Insights Enabled: false\\r\\nApplication Insights Key: None\\r\\nInferencing HTTP server version: azmlinfsrv/0.7.7\\r\\nCORS for the specified origins: None\\r\\n\\r\\n\\r\\nServer Routes\\r\\n---------------\\r\\nLiveness Probe: GET   127.0.0.1:31311/\\r\\nScore:          POST  127.0.0.1:31311/score\\r\\n\\r\\nStarting gunicorn 20.1.0\\r\\nListening at: http://0.0.0.0:31311 (28)\\r\\nUsing worker: sync\\r\\nBooting worker with pid: 89\\r\\nInitializing logger\\r\\nStarting up app insights client\\r\\n2023-09-05 10:13:22,521 | root | INFO | Starting up app insights client\\r\\nlogging socket was found. logging is available.\\r\\nlogging socket was found. logging is available.\\r\\nStarting up app insight hooks\\r\\n2023-09-05 10:13:22,528 | root | INFO | Starting up app insight hooks\\r\\ntorchvision is not available - cannot save figures\\r\\n2023-09-05 10:13:24,186 | speechbrain.utils.train_logger | WARNING | torchvision is not available - cannot save figures\\r\\nFound user script at /var/azureml-app/Inference/score.py\\r\\n2023-09-05 10:13:24,195 | root | INFO | Found user script at /var/azureml-app/Inference/score.py\\r\\nrun() is not decorated. Server will invoke it with the input in JSON string.\\r\\n2023-09-05 10:13:24,195 | root | INFO | run() is not decorated. Server will invoke it with the input in JSON string.\\r\\nInvoking user's init function\\r\\n2023-09-05 10:13:24,195 | root | INFO | Invoking user's init function\\r\\nFetch hyperparams.yaml: Delegating to Huggingface hub, source Sunbird/sunbird-lug-tts.\\r\\n2023-09-05 10:13:24,230 | speechbrain.pretrained.fetching | INFO | Fetch hyperparams.yaml: Delegating to Huggingface hub, source Sunbird/sunbird-lug-tts.\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)ain/hyperparams.yaml:   0% 0.00/2.06k [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)ain/hyperparams.yaml: 100% 2.06k/2.06k [00:00<00:00, 575kB/s]\\r\\nHF fetch: /root/.cache/huggingface/hub/models--Sunbird--sunbird-lug-tts/snapshots/299de3591dbfae7732a1abebf3bea8ff339d1298/hyperparams.yaml\\r\\n2023-09-05 10:13:24,376 | speechbrain.pretrained.fetching | INFO | HF fetch: /root/.cache/huggingface/hub/models--Sunbird--sunbird-lug-tts/snapshots/299de3591dbfae7732a1abebf3bea8ff339d1298/hyperparams.yaml\\r\\nFetch custom.py: Delegating to Huggingface hub, source Sunbird/sunbird-lug-tts.\\r\\n2023-09-05 10:13:24,436 | speechbrain.pretrained.fetching | INFO | Fetch custom.py: Delegating to Huggingface hub, source Sunbird/sunbird-lug-tts.\\r\\nFetch model.ckpt: Delegating to Huggingface hub, source Sunbird/sunbird-lug-tts.\\r\\n2023-09-05 10:13:24,766 | speechbrain.pretrained.fetching | INFO | Fetch model.ckpt: Delegating to Huggingface hub, source Sunbird/sunbird-lug-tts.\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt:   0% 0.00/113M [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt:  19% 21.0M/113M [00:00<00:00, 113MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt:  37% 41.9M/113M [00:00<00:00, 98.7MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt:  56% 62.9M/113M [00:00<00:00, 92.5MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt:  74% 83.9M/113M [00:01<00:00, 69.5MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt:  84% 94.4M/113M [00:01<00:00, 72.4MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt: 100% 113M/113M [00:01<00:00, 89.4MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading model.ckpt: 100% 113M/113M [00:01<00:00, 85.2MB/s]\\r\\nHF fetch: /root/.cache/huggingface/hub/models--Sunbird--sunbird-lug-tts/snapshots/299de3591dbfae7732a1abebf3bea8ff339d1298/model.ckpt\\r\\n2023-09-05 10:13:26,335 | speechbrain.pretrained.fetching | INFO | HF fetch: /root/.cache/huggingface/hub/models--Sunbird--sunbird-lug-tts/snapshots/299de3591dbfae7732a1abebf3bea8ff339d1298/model.ckpt\\r\\nLoading pretrained files for: model\\r\\n2023-09-05 10:13:26,396 | speechbrain.utils.parameter_transfer | INFO | Loading pretrained files for: model\\r\\nFetch hyperparams.yaml: Delegating to Huggingface hub, source speechbrain/tts-hifigan-ljspeech.\\r\\n2023-09-05 10:13:26,512 | speechbrain.pretrained.fetching | INFO | Fetch hyperparams.yaml: Delegating to Huggingface hub, source speechbrain/tts-hifigan-ljspeech.\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)ain/hyperparams.yaml:   0% 0.00/1.16k [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading (…)ain/hyperparams.yaml: 100% 1.16k/1.16k [00:00<00:00, 1.03MB/s]\\r\\nHF fetch: /root/.cache/huggingface/hub/models--speechbrain--tts-hifigan-ljspeech/snapshots/e0cc1f9be5b65d4612013f26867ca600e98bc1b6/hyperparams.yaml\\r\\n2023-09-05 10:13:26,553 | speechbrain.pretrained.fetching | INFO | HF fetch: /root/.cache/huggingface/hub/models--speechbrain--tts-hifigan-ljspeech/snapshots/e0cc1f9be5b65d4612013f26867ca600e98bc1b6/hyperparams.yaml\\r\\nFetch custom.py: Delegating to Huggingface hub, source speechbrain/tts-hifigan-ljspeech.\\r\\n2023-09-05 10:13:26,620 | speechbrain.pretrained.fetching | INFO | Fetch custom.py: Delegating to Huggingface hub, source speechbrain/tts-hifigan-ljspeech.\\r\\nFetch generator.ckpt: Delegating to Huggingface hub, source speechbrain/tts-hifigan-ljspeech.\\r\\n2023-09-05 10:13:26,856 | speechbrain.pretrained.fetching | INFO | Fetch generator.ckpt: Delegating to Huggingface hub, source speechbrain/tts-hifigan-ljspeech.\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading generator.ckpt:   0% 0.00/55.8M [00:00<?, ?B/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading generator.ckpt:  38% 21.0M/55.8M [00:00<00:00, 99.6MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading generator.ckpt:  75% 41.9M/55.8M [00:00<00:00, 98.0MB/s]\\r\\n00000000-0000-0000-0000-000000000000,\\rDownloading generator.ckpt: 100% 55.8M/55.8M [00:00<00:00, 116MB/s]\\r\\nHF fetch: /root/.cache/huggingface/hub/models--speechbrain--tts-hifigan-ljspeech/snapshots/e0cc1f9be5b65d4612013f26867ca600e98bc1b6/generator.ckpt\\r\\n2023-09-05 10:13:27,486 | speechbrain.pretrained.fetching | INFO | HF fetch: /root/.cache/huggingface/hub/models--speechbrain--tts-hifigan-ljspeech/snapshots/e0cc1f9be5b65d4612013f26867ca600e98bc1b6/generator.ckpt\\r\\nLoading pretrained files for: generator\\r\\n2023-09-05 10:13:27,541 | speechbrain.utils.parameter_transfer | INFO | Loading pretrained files for: generator\\r\\nInit complete\\r\\n2023-09-05 10:13:27,605 | root | INFO | Init complete\\r\\nUsers's init has completed successfully\\r\\n2023-09-05 10:13:27,606 | root | INFO | Users's init has completed successfully\\r\\nSwaggers are prepared for the following versions: [2, 3].\\r\\n2023-09-05 10:13:27,615 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\r\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\r\\n2023-09-05 10:13:27,615 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\r\\nAML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\r\\n2023-09-05 10:13:27,615 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\r\\n\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=endpoint_name, local=True, lines=500\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1693908841744
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Succeeded', 'scoring_uri': 'http://localhost:32782/score', 'openapi_uri': None, 'name': 'lugtts-endpt-09050932965776', 'description': 'This is the endpoint for inferencing text to speech in luganda', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/oasisaitts/code/Users/2100800280/OasisAiTextToSpeech'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f341c1bce50>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.get(name=endpoint_name, local=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1693908862063
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"blob_url\": \"https://oasisaigenerated.blob.core.windows.net/generatedaudiolug/audio-20230905-101421.wav\"}'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=endpoint_name,\n",
        "    request_file=\"sample-request.json\",\n",
        "    local=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1693908224362
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py\", line 852, in upload\\r\\n    map_error(status_code=response.status_code, response=response, error_map=error_map)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/exceptions.py\", line 164, in map_error\\r\\n    raise error\\r\\nazure.core.exceptions.ResourceExistsError: The specified blob already exists.\\r\\nRequestId:ab63d1cb-f01e-0038-45e0-df3f45000000\\r\\nTime:2023-09-05T10:03:05.3971723Z\\r\\nErrorCode:BlobAlreadyExists\\r\\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobAlreadyExists</Code><Message>The specified blob already exists.\\r\\nRequestId:ab63d1cb-f01e-0038-45e0-df3f45000000\\r\\nTime:2023-09-05T10:03:05.3971723Z</Message></Error>\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/routes.py\", line 210, in handle_score\\r\\n    timed_result = app.user_script.invoke_run(request, timeout_ms=app.scoring_timeout_in_ms)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 136, in invoke_run\\r\\n    raise UserScriptException(ex) from ex\\r\\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\\r\\n\\r\\n2023-09-05 10:03:05,410 | root | ERROR | Encountered Exception: Traceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 129, in invoke_run\\r\\n    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 156, in <lambda>\\r\\n    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\\r\\n  File \"/var/azureml-app/Inference/score.py\", line 72, in run\\r\\n    blob_client.upload_blob(data)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_blob_client.py\", line 737, in upload_blob\\r\\n    return upload_block_blob(**options)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py\", line 195, in upload_block_blob\\r\\n    process_storage_error(error)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_shared/response_handlers.py\", line 189, in process_storage_error\\r\\n    exec(\"raise error from None\")   # pylint: disable=exec-used # nosec\\r\\n  File \"<string>\", line 1, in <module>\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py\", line 105, in upload_block_blob\\r\\n    response = client.upload(\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py\", line 852, in upload\\r\\n    map_error(status_code=response.status_code, response=response, error_map=error_map)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/exceptions.py\", line 164, in map_error\\r\\n    raise error\\r\\nazure.core.exceptions.ResourceExistsError: The specified blob already exists.\\r\\nRequestId:ab63d1cb-f01e-0038-45e0-df3f45000000\\r\\nTime:2023-09-05T10:03:05.3971723Z\\r\\nErrorCode:BlobAlreadyExists\\r\\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobAlreadyExists</Code><Message>The specified blob already exists.\\r\\nRequestId:ab63d1cb-f01e-0038-45e0-df3f45000000\\r\\nTime:2023-09-05T10:03:05.3971723Z</Message></Error>\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/routes.py\", line 210, in handle_score\\r\\n    timed_result = app.user_script.invoke_run(request, timeout_ms=app.scoring_timeout_in_ms)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 136, in invoke_run\\r\\n    raise UserScriptException(ex) from ex\\r\\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\\r\\n\\r\\n500\\r\\n2023-09-05 10:03:05,410 | root | INFO | 500\\r\\n127.0.0.1 - - [05/Sep/2023:10:03:05 +0000] \"POST /score HTTP/1.0\" 500 370 \"-\" \"azure-ai-ml/1.9.0 azsdk-python-core/1.29.3 Python/3.8.5 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.10)\"\\r\\nRequest URL: \\'https://oasisaigenerated.blob.core.windows.net/generatedaudiolug/temp.wav\\'\\r\\nRequest method: \\'PUT\\'\\r\\nRequest headers:\\r\\n    \\'Content-Length\\': \\'2307130\\'\\r\\n    \\'x-ms-blob-type\\': \\'REDACTED\\'\\r\\n    \\'If-None-Match\\': \\'*\\'\\r\\n    \\'x-ms-version\\': \\'REDACTED\\'\\r\\n    \\'Content-Type\\': \\'application/octet-stream\\'\\r\\n    \\'Accept\\': \\'application/xml\\'\\r\\n    \\'User-Agent\\': \\'azsdk-python-storage-blob/12.17.0 Python/3.9.0 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.27)\\'\\r\\n    \\'x-ms-date\\': \\'REDACTED\\'\\r\\n    \\'x-ms-client-request-id\\': \\'74e23756-4bd3-11ee-a54e-0242ac110002\\'\\r\\n    \\'Authorization\\': \\'REDACTED\\'\\r\\nA body is sent with the request\\r\\n2023-09-05 10:03:26,623 | azure.core.pipeline.policies.http_logging_policy | INFO | Request URL: \\'https://oasisaigenerated.blob.core.windows.net/generatedaudiolug/temp.wav\\'\\r\\nRequest method: \\'PUT\\'\\r\\nRequest headers:\\r\\n    \\'Content-Length\\': \\'2307130\\'\\r\\n    \\'x-ms-blob-type\\': \\'REDACTED\\'\\r\\n    \\'If-None-Match\\': \\'*\\'\\r\\n    \\'x-ms-version\\': \\'REDACTED\\'\\r\\n    \\'Content-Type\\': \\'application/octet-stream\\'\\r\\n    \\'Accept\\': \\'application/xml\\'\\r\\n    \\'User-Agent\\': \\'azsdk-python-storage-blob/12.17.0 Python/3.9.0 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.27)\\'\\r\\n    \\'x-ms-date\\': \\'REDACTED\\'\\r\\n    \\'x-ms-client-request-id\\': \\'74e23756-4bd3-11ee-a54e-0242ac110002\\'\\r\\n    \\'Authorization\\': \\'REDACTED\\'\\r\\nA body is sent with the request\\r\\nResponse status: 409\\r\\nResponse headers:\\r\\n    \\'Content-Length\\': \\'220\\'\\r\\n    \\'Content-Type\\': \\'application/xml\\'\\r\\n    \\'Server\\': \\'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0\\'\\r\\n    \\'x-ms-request-id\\': \\'799cba0c-001e-0003-6fe0-df7ae1000000\\'\\r\\n    \\'x-ms-client-request-id\\': \\'74e23756-4bd3-11ee-a54e-0242ac110002\\'\\r\\n    \\'x-ms-version\\': \\'REDACTED\\'\\r\\n    \\'x-ms-error-code\\': \\'BlobAlreadyExists\\'\\r\\n    \\'Date\\': \\'Tue, 05 Sep 2023 10:03:25 GMT\\'\\r\\n2023-09-05 10:03:26,740 | azure.core.pipeline.policies.http_logging_policy | INFO | Response status: 409\\r\\nResponse headers:\\r\\n    \\'Content-Length\\': \\'220\\'\\r\\n    \\'Content-Type\\': \\'application/xml\\'\\r\\n    \\'Server\\': \\'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0\\'\\r\\n    \\'x-ms-request-id\\': \\'799cba0c-001e-0003-6fe0-df7ae1000000\\'\\r\\n    \\'x-ms-client-request-id\\': \\'74e23756-4bd3-11ee-a54e-0242ac110002\\'\\r\\n    \\'x-ms-version\\': \\'REDACTED\\'\\r\\n    \\'x-ms-error-code\\': \\'BlobAlreadyExists\\'\\r\\n    \\'Date\\': \\'Tue, 05 Sep 2023 10:03:25 GMT\\'\\r\\nEncountered Exception: Traceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 129, in invoke_run\\r\\n    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 156, in <lambda>\\r\\n    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\\r\\n  File \"/var/azureml-app/Inference/score.py\", line 72, in run\\r\\n    blob_client.upload_blob(data)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_blob_client.py\", line 737, in upload_blob\\r\\n    return upload_block_blob(**options)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py\", line 195, in upload_block_blob\\r\\n    process_storage_error(error)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_shared/response_handlers.py\", line 189, in process_storage_error\\r\\n    exec(\"raise error from None\")   # pylint: disable=exec-used # nosec\\r\\n  File \"<string>\", line 1, in <module>\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py\", line 105, in upload_block_blob\\r\\n    response = client.upload(\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py\", line 852, in upload\\r\\n    map_error(status_code=response.status_code, response=response, error_map=error_map)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/exceptions.py\", line 164, in map_error\\r\\n    raise error\\r\\nazure.core.exceptions.ResourceExistsError: The specified blob already exists.\\r\\nRequestId:799cba0c-001e-0003-6fe0-df7ae1000000\\r\\nTime:2023-09-05T10:03:26.7381566Z\\r\\nErrorCode:BlobAlreadyExists\\r\\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobAlreadyExists</Code><Message>The specified blob already exists.\\r\\nRequestId:799cba0c-001e-0003-6fe0-df7ae1000000\\r\\nTime:2023-09-05T10:03:26.7381566Z</Message></Error>\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/routes.py\", line 210, in handle_score\\r\\n    timed_result = app.user_script.invoke_run(request, timeout_ms=app.scoring_timeout_in_ms)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 136, in invoke_run\\r\\n    raise UserScriptException(ex) from ex\\r\\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\\r\\n\\r\\n2023-09-05 10:03:26,752 | root | ERROR | Encountered Exception: Traceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 129, in invoke_run\\r\\n    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 156, in <lambda>\\r\\n    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)\\r\\n  File \"/var/azureml-app/Inference/score.py\", line 72, in run\\r\\n    blob_client.upload_blob(data)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_blob_client.py\", line 737, in upload_blob\\r\\n    return upload_block_blob(**options)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py\", line 195, in upload_block_blob\\r\\n    process_storage_error(error)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_shared/response_handlers.py\", line 189, in process_storage_error\\r\\n    exec(\"raise error from None\")   # pylint: disable=exec-used # nosec\\r\\n  File \"<string>\", line 1, in <module>\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_upload_helpers.py\", line 105, in upload_block_blob\\r\\n    response = client.upload(\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/tracing/decorator.py\", line 78, in wrapper_use_tracer\\r\\n    return func(*args, **kwargs)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py\", line 852, in upload\\r\\n    map_error(status_code=response.status_code, response=response, error_map=error_map)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azure/core/exceptions.py\", line 164, in map_error\\r\\n    raise error\\r\\nazure.core.exceptions.ResourceExistsError: The specified blob already exists.\\r\\nRequestId:799cba0c-001e-0003-6fe0-df7ae1000000\\r\\nTime:2023-09-05T10:03:26.7381566Z\\r\\nErrorCode:BlobAlreadyExists\\r\\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobAlreadyExists</Code><Message>The specified blob already exists.\\r\\nRequestId:799cba0c-001e-0003-6fe0-df7ae1000000\\r\\nTime:2023-09-05T10:03:26.7381566Z</Message></Error>\\r\\n\\r\\nThe above exception was the direct cause of the following exception:\\r\\n\\r\\nTraceback (most recent call last):\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/routes.py\", line 210, in handle_score\\r\\n    timed_result = app.user_script.invoke_run(request, timeout_ms=app.scoring_timeout_in_ms)\\r\\n  File \"/opt/miniconda/envs/inf-conda-env/lib/python3.9/site-packages/azureml_inference_server_http/server/user_script.py\", line 136, in invoke_run\\r\\n    raise UserScriptException(ex) from ex\\r\\nazureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script\\r\\n\\r\\n500\\r\\n2023-09-05 10:03:26,752 | root | INFO | 500\\r\\n127.0.0.1 - - [05/Sep/2023:10:03:26 +0000] \"POST /score HTTP/1.0\" 500 370 \"-\" \"azure-ai-ml/1.9.0 azsdk-python-core/1.29.3 Python/3.8.5 (Linux-5.15.0-1040-azure-x86_64-with-glibc2.10)\"\\r\\n'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_deployments.get_logs(\n",
        "    name=\"blue\", endpoint_name=endpoint_name, local=True, lines=200\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - Pytorch and Tensorflow",
      "language": "python",
      "name": "python38-azureml-pt-tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
